# idea
for Support Vector Machine Linear: use a linear model and try to find a decision boundary (hyperplane) that best separates data. the best hyperplane is the one that yields the largest separation/margin between both classes. so we choose the hyperplane so that the distance from it to the nearest datapoint on each size is maximined.
“The nearest data points are the support vectors. All of these data points, when projected onto the hyperplane 
𝑤⋅𝑥 + 𝑏, will equal 1 or -1, while the data points lying outside the margin will be greater than 1 or less than -1.
<img width="1375" height="572" alt="{214C0377-8CD9-4C63-8434-FD80B1F4B8EB}" src="https://github.com/user-attachments/assets/edcaabbc-8500-46ff-9947-fdfccd84b270" />
