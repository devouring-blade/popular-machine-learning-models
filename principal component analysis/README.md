
1. Objective
Find a new axis ğ‘£ (unit vector) so that when projecting data ğ‘¥ğ‘– onto it, the variance of the projected data is maximized.
Reduce dimensionality by keeping axes with the largest variance.

2. Data Standardization
Gaussian standardization: ğ‘¥ğ‘– = (ğ‘¥ğ‘–âˆ’mean(ğ‘¥ğ‘–)) / std(ğ‘¥ğ‘–).
After this step, mean(ğ‘¥ğ‘–) = 0.
Meaning: centering data around the origin helps identify the â€œdirection of maximum spreadâ€ and balances features with different ranges.

3. Projecting Data onto the New Axis
For one point: ğ‘§ğ‘– = ğ‘£^ğ‘‡.ğ‘¥ğ‘–
For all data: ğ‘ = ğ‘‹.ğ‘£

4. Variance of Projected Data
Var(z) = (1/n).Î£(zi âˆ’ zÌ„)Â²
After centering (Î¼=0): Var(z) = (1/n).Î£(ziÂ²) = (1/n).(Xv)^T.(Xv) = v^T.A.v
where A = (1/n).X^T.X (covariance matrix)

5. Constrained Optimization
Maximize J(v) = v^T.A.v
Constraint: v^T.v = 1
Lagrangian: L(v, Î») = v^T.A.v âˆ’ Î».(v^T.v âˆ’ 1)
Derivative to find the extremum to maximize with respect to ğ‘£: A.v = Î».v

6. Finding Eigenvalues & Eigenvectors
Equation: (A âˆ’ Î»I)v = 0
Non-trivial solutions exist only if det(A âˆ’ Î»I) = 0
Solve for Î» (eigenvalues) and v (eigenvectors), then normalize v

7. Interpretation of Results
Eigenvector v = direction of the new axis
Eigenvalue Î» = variance along that axis

8. Principal Components
Sort eigenvalues in descending order
Choose k eigenvectors with largest Î» â†’ Vk
Project data: Z = X Â· Vk
